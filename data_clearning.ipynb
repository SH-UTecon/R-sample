{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データ結合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>PANEL</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>...</th>\n",
       "      <th>P186D</th>\n",
       "      <th>P186E</th>\n",
       "      <th>P186F</th>\n",
       "      <th>P186G</th>\n",
       "      <th>P186H</th>\n",
       "      <th>P186I</th>\n",
       "      <th>P186J</th>\n",
       "      <th>P186K</th>\n",
       "      <th>P186L</th>\n",
       "      <th>P186M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>99999</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>99999</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>99999</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>99999</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>99999</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53978</th>\n",
       "      <td>5648</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>99999</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53979</th>\n",
       "      <td>5648</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>99999</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53980</th>\n",
       "      <td>5648</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>99999</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53981</th>\n",
       "      <td>5648</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>99999</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53982</th>\n",
       "      <td>5648</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>99999</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53983 rows × 3053 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID  PANEL  Q1  Q2  Q3     Q4  Q5  Q6  Q7  Q8  ...  P186D  P186E  \\\n",
       "0         1      1   2   3   2  99999   2   0   2  32  ...    NaN    NaN   \n",
       "1         1      2   2   3   2  99999   2   0   2  33  ...    NaN    NaN   \n",
       "2         1      3   1   3   2  99999   2   0   2  34  ...    NaN    NaN   \n",
       "3         1      4   1   3   2  99999   3   0   2  35  ...    NaN    NaN   \n",
       "4         1      5   1   3   2  99999   6   0   2  36  ...    NaN    NaN   \n",
       "...     ...    ...  ..  ..  ..    ...  ..  ..  ..  ..  ...    ...    ...   \n",
       "53978  5648     25   2   8   2  99999   2   0   2  30  ...    NaN    NaN   \n",
       "53979  5648     26   2   8   2  99999   2   0   2  31  ...    NaN    NaN   \n",
       "53980  5648     27   2   8   2  99999   2   0   2  32  ...    NaN    NaN   \n",
       "53981  5648     28   2   8   2  99999   2   0   2  33  ...    NaN    NaN   \n",
       "53982  5648     29   2   8   2  99999   2   0   2  34  ...    NaN    NaN   \n",
       "\n",
       "       P186F  P186G  P186H  P186I  P186J  P186K  P186L  P186M  \n",
       "0        NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "1        NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "2        NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "3        NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "4        NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "53978    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "53979    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "53980    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "53981    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "53982    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "\n",
       "[53983 rows x 3053 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# データセットのファイル構造を定義\n",
    "dataset_parts = {\n",
    "    'p5': ['p5a', 'p5b'],\n",
    "    'p11': ['p11ab', 'p11c'],\n",
    "    'p16': ['p16abc', 'p16d'],\n",
    "    'p21': ['p21abcd', 'p21e']\n",
    "}\n",
    "\n",
    "# 通常のデータセットはp1からp29まで\n",
    "all_datasets = [f'p{i}' for i in range(1, 30)]\n",
    "\n",
    "# 特殊処理をするデータセットを除外\n",
    "regular_datasets = [d for d in all_datasets if d not in dataset_parts]\n",
    "\n",
    "# データを格納する辞書\n",
    "data_dict = {}\n",
    "\n",
    "# 通常のデータを処理\n",
    "for dataset in regular_datasets:\n",
    "    part_files = [f'../Data_JPSC/JPSC_general/data/{dataset}/{dataset}_{i}.csv' for i in range(1, 4)]\n",
    "    merged_data = pd.read_csv(part_files[0])\n",
    "    for part in part_files[1:]:\n",
    "        merged_data = pd.merge(merged_data, pd.read_csv(part), on=['ID', 'PANEL'], how='inner')\n",
    "    data_dict[dataset] = merged_data\n",
    "\n",
    "# 特殊な構造を持つデータを処理\n",
    "for key, parts in dataset_parts.items():\n",
    "    part_dataframes = []\n",
    "    for part in parts:\n",
    "        part_files = [f'../Data_JPSC/JPSC_general/data/{part}/{part}_1.csv',\n",
    "                      f'../Data_JPSC/JPSC_general/data/{part}/{part}_2.csv',\n",
    "                      f'../Data_JPSC/JPSC_general/data/{part}/{part}_3.csv']\n",
    "        merged_part_data = pd.read_csv(part_files[0])\n",
    "        for part_file in part_files[1:]:\n",
    "            merged_part_data = pd.merge(merged_part_data, pd.read_csv(part_file), on=['ID', 'PANEL'], how='inner')\n",
    "        part_dataframes.append(merged_part_data)\n",
    "    # p5, p11, p16, p21の2つのパートを結合\n",
    "    data_dict[key] = pd.concat(part_dataframes, axis=0)\n",
    "\n",
    "# 最後に全てのデータを結合\n",
    "data = pd.concat(data_dict.values(), axis=0)\n",
    "data = data.drop(columns=['REC','REC_x','REC_y'])\n",
    "data = data.sort_values(by=['ID','PANEL'])\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# データフレームの出力\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_original = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 欠損値処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第1子が生まれたか"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 子どもの人数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Q57'] = data['Q57'].apply(lambda x: np.nan if isinstance(x, (int, float)) and x >= 8 else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 収入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3Q7 問７．あなたの仕事の給与は、時給計算ですか、日給計算ですか。\n",
    "# 妻の給料\n",
    "\n",
    "# 月給 19662 non-null\n",
    "data['Q149'] = data['Q149'].apply(lambda x: np.nan if isinstance(x, (int, float)) and x >= 9998 else x)\n",
    "#万円単位に変換\n",
    "data['Q149'] = data['Q149'].apply(lambda x: x/10)\n",
    "# 日給 1470 non-null\n",
    "data['Q150'] = data['Q150'].apply(lambda x: np.nan if isinstance(x, (int, float)) and x >= 99998 else x)\n",
    "# 時給 13509 non-null\n",
    "data['Q151'] = data['Q151'].apply(lambda x: np.nan if isinstance(x, (int, float)) and x >= 99998 else x)\n",
    "\n",
    "\n",
    "# 4Q7 問７．ご主人のお仕事の給与は、時給計算ですか、日給計算ですか。\n",
    "# 夫の給料\n",
    "\n",
    "# 月給 28678 non-null\n",
    "data['Q220'] = data['Q220'].apply(lambda x: np.nan if isinstance(x, (int, float)) and x >= 9998 else x)\n",
    "#万円単位に変換\n",
    "data['Q220'] = data['Q220'].apply(lambda x: x/10)\n",
    "# 日給 2155 non-null\n",
    "data['Q221'] = data['Q221'].apply(lambda x: np.nan if isinstance(x, (int, float)) and x >= 99998 else x)\n",
    "# 時給 498 non-null\n",
    "data['Q222'] = data['Q222'].apply(lambda x: np.nan if isinstance(x, (int, float)) and x >= 99998 else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 月収"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6Q9．この９月の手取り収入（収入総額から税金、社会保険料などを差し引いた額）はどのくらいですか。（ボーナス、臨時の給与は除きます）\n",
    "#夫の手取り\n",
    "data['Q307B'] = data['Q307B'].apply(lambda x: np.nan if isinstance(x, (int, float)) and x >= 998 else x)\n",
    "#妻の手取り\n",
    "data['Q308B'] = data['Q308B'].apply(lambda x: np.nan if isinstance(x, (int, float)) and x >= 998 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#夫の年収\n",
    "Q296 = ['Q296A', 'Q296B', 'Q296C', 'Q296D', 'Q296E', 'Q296F']\n",
    "for column in Q296:\n",
    "    data[column] = data[column].apply(lambda x: np.nan if isinstance(x, (int, float)) and x >= 9998 else x)\n",
    "\n",
    "#妻の年収\n",
    "Q297 = ['Q297A', 'Q297B', 'Q297C', 'Q297D', 'Q297E', 'Q297F']\n",
    "for column in Q297:\n",
    "    data[column] = data[column].apply(lambda x: np.nan if isinstance(x, (int, float)) and x >= 9998 else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ouhsj\\AppData\\Local\\Temp\\ipykernel_22940\\3232106426.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['HH_Total_Inc'] = data['Q296F'] + data['Q297F']\n"
     ]
    }
   ],
   "source": [
    "data['HH_Total_Inc'] = data['Q296F'] + data['Q297F']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9月の月収を推定するコード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 夫の収入を推定する関数\n",
    "def estimate_husband_income(row):\n",
    "    # Q307Bが欠損値でなければその値を使用\n",
    "    if not pd.isna(row[\"Q307B\"]):\n",
    "        return row[\"Q307B\"]\n",
    "    \n",
    "    # Q307Bが欠損値の場合、Q220を使用\n",
    "    elif not pd.isna(row[\"Q220\"]):\n",
    "        return row[\"Q220\"]\n",
    "    \n",
    "    # Q220も欠損値の場合、Q296A / 12 を使用\n",
    "    elif not pd.isna(row[\"Q296A\"]):\n",
    "        return row[\"Q296A\"] / 12\n",
    "    \n",
    "    # Q296Aも欠損値の場合、Q296B / 12 を使用\n",
    "    elif not pd.isna(row[\"Q296B\"]):\n",
    "        return row[\"Q296B\"] / 12\n",
    "    \n",
    "    # すべてが欠損値の場合は np.nan を返す\n",
    "    return np.nan\n",
    "\n",
    "# 妻の収入を推定する関数\n",
    "def estimate_wife_income(row):\n",
    "    # Q308Bが欠損値でなければその値を使用\n",
    "    if not pd.isna(row[\"Q308B\"]):\n",
    "        return row[\"Q308B\"]\n",
    "    \n",
    "    # Q308Bが欠損値の場合、Q149を使用\n",
    "    elif not pd.isna(row[\"Q149\"]):\n",
    "        return row[\"Q149\"]\n",
    "    \n",
    "    # Q149も欠損値の場合、Q297A / 12 を使用\n",
    "    elif not pd.isna(row[\"Q297A\"]):\n",
    "        return row[\"Q297A\"] / 12\n",
    "    \n",
    "    # Q297Aも欠損値の場合、Q297B / 12 を使用\n",
    "    elif not pd.isna(row[\"Q297B\"]):\n",
    "        return row[\"Q297B\"] / 12\n",
    "    \n",
    "    # すべてが欠損値の場合は np.nan を返す\n",
    "    return np.nan\n",
    "\n",
    "# データフレームに対して適用する\n",
    "data[\"H_Inc_Sept\"] = data.apply(estimate_husband_income, axis=1)\n",
    "data[\"W_Inc_Sept\"] = data.apply(estimate_wife_income, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 時間配分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 労働時間\n",
    "data['Q152'] = data['Q152'].apply(lambda x: np.nan if isinstance(x, (int, float)) and x >= 11 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours = [\n",
    "    \"Q493AH\", \"Q493BH\", \"Q493CH\", \"Q493DH\", \"Q493IH\", \"Q493MH\", #妻 平日\n",
    "    \"Q494AH\", \"Q494BH\", \"Q494CH\", \"Q494DH\", \"Q494IH\", \"Q494MH\", #妻 休日\n",
    "    \"Q495AH\", \"Q495BH\", \"Q495CH\", \"Q495DH\", \"Q495IH\", \"Q495MH\", #夫 平日\n",
    "    \"Q496AH\", \"Q496BH\", \"Q496CH\", \"Q496DH\", \"Q496IH\", \"Q496MH\"  #夫 休日\n",
    "    ]\n",
    "minutes = [\n",
    "    \"Q493AM\", \"Q493BM\", \"Q493CM\", \"Q493DM\", \"Q493IM\", \"Q493MM\", #妻 平日\n",
    "    \"Q494AM\", \"Q494BM\", \"Q494CM\", \"Q494DM\", \"Q494IM\", \"Q494MM\", #妻 休日\n",
    "    \"Q495AM\", \"Q495BM\", \"Q495CM\", \"Q495DM\", \"Q495IM\", \"Q495MM\", #夫 平日\n",
    "    \"Q496AH\", \"Q496BM\", \"Q496CH\", \"Q496DM\", \"Q496IM\", \"Q496MM\" #夫 休日\n",
    "    ]\n",
    "\n",
    "for column in hours:\n",
    "    data[column] = data[column].apply(lambda x: np.nan if isinstance(x, (int, float)) and x > 24 else x)\n",
    "    data[column] = data[column].apply(lambda x: x*60)\n",
    "\n",
    "for column in minutes:\n",
    "    data[column] = data[column].apply(lambda x: np.nan if isinstance(x, (int, float)) and x > 6 else x)\n",
    "    data[column] = data[column].apply(lambda x: x*10)\n",
    "\n",
    "# Create new columns based on hours and minutes\n",
    "# 単位は時間\n",
    "for hour_col, min_col in zip(hours, minutes):\n",
    "    new_col = hour_col[:-1]  # New column name, e.g., Q493A\n",
    "    data[new_col] = data[hour_col] + data[min_col]\n",
    "    data[new_col] = data[new_col].apply(lambda x: x/60)\n",
    "    data[new_col] = data[new_col].apply(lambda x: np.nan if isinstance(x, (int, float)) and x > 24 else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 家事の割合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 問29．炊事・洗濯・掃除などの家事について、ご夫婦でどの程度分担しあっていますか。全体を100％としたときの、それぞれの貢献分をお答えください。\n",
    "data['Q1233A'] = data['Q1233A'].apply(lambda x: np.nan if isinstance(x, (int, float)) and x >= 998 else x)\n",
    "data['Q1233B'] = data['Q1233A'].apply(lambda x: np.nan if isinstance(x, (int, float)) and x >= 998 else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 支出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 置き換える対象の列\n",
    "columns_6Q1 = [\n",
    "    'Q293A', 'Q293B', 'Q293C', 'Q293E', 'Q293F', 'Q293G', #支出\n",
    "    'Q294A', 'Q294B', 'Q294C', 'Q294D', 'Q294E', 'Q294F',  #貯蓄\n",
    "    'Q295' #ローン返済\n",
    "]\n",
    "\n",
    "for column in columns_6Q1:\n",
    "    data[column] = data[column].apply(lambda x: np.nan if isinstance(x, (int, float)) and x >= 998 else x)\n",
    "    data[column] = data[column].apply(lambda x: x/10) #万円単位に換算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ouhsj\\AppData\\Local\\Temp\\ipykernel_22940\\382811819.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['C_plus_S_Other_Ratio'] = data['C_plus_S_Other'] / data['C_plus_S_Total']\n",
      "C:\\Users\\ouhsj\\AppData\\Local\\Temp\\ipykernel_22940\\382811819.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['C_plus_S_Public_Ratio'] = data['C_plus_S_Public'] / data['C_plus_S_Total']\n"
     ]
    }
   ],
   "source": [
    "# 'Q293A'と'Q294A'を合計し、新しい列を作成\n",
    "data['C_plus_S_Total'] = data['Q293A'] + data['Q294A']\n",
    "data['C_plus_S_All'] = data['Q293B'] + data['Q294B']\n",
    "data['C_plus_S_Wife'] = data['Q293C'] + data['Q294C']\n",
    "data['C_plus_S_Husband'] = data['Q293E'] + data['Q294D']\n",
    "data['C_plus_S_Child'] = data['Q293F'] + data['Q294E']\n",
    "data['C_plus_S_Other'] = data['Q293G'] + data['Q294F']\n",
    "\n",
    "data['C_plus_S_Public'] = data['C_plus_S_All'] + data['C_plus_S_Other']\n",
    "\n",
    "# 比率を計算\n",
    "data['C_plus_S_All_Ratio'] = data['C_plus_S_All'] / data['C_plus_S_Total']\n",
    "data['C_plus_S_Wife_Ratio'] = data['C_plus_S_Wife']  / data['C_plus_S_Total']\n",
    "data['C_plus_S_Husband_Ratio'] = data['C_plus_S_Husband'] / data['C_plus_S_Total']\n",
    "data['C_plus_S_Child_Ratio'] = data['C_plus_S_Child'] / data['C_plus_S_Total']\n",
    "data['C_plus_S_Other_Ratio'] = data['C_plus_S_Other'] / data['C_plus_S_Total']\n",
    "data['C_plus_S_Public_Ratio'] = data['C_plus_S_Public'] / data['C_plus_S_Total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ouhsj\\AppData\\Local\\Temp\\ipykernel_22940\\3938519938.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['Cons_All_Ratio'] = data['Cons_All'] / data['Cons_Total']\n",
      "C:\\Users\\ouhsj\\AppData\\Local\\Temp\\ipykernel_22940\\3938519938.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['Cons_Wife_Ratio'] = data['Cons_Wife']  / data['Cons_Total']\n",
      "C:\\Users\\ouhsj\\AppData\\Local\\Temp\\ipykernel_22940\\3938519938.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['Cons_Husband_Ratio'] = data['Cons_Husband'] / data['Cons_Total']\n",
      "C:\\Users\\ouhsj\\AppData\\Local\\Temp\\ipykernel_22940\\3938519938.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['Cons_Child_Ratio'] = data['Cons_Child'] / data['Cons_Total']\n",
      "C:\\Users\\ouhsj\\AppData\\Local\\Temp\\ipykernel_22940\\3938519938.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['Cons_Other_Ratio'] = data['Cons_Other'] / data['Cons_Total']\n",
      "C:\\Users\\ouhsj\\AppData\\Local\\Temp\\ipykernel_22940\\3938519938.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['Cons_Public'] = data['Cons_All'] + data['Cons_Other']\n",
      "C:\\Users\\ouhsj\\AppData\\Local\\Temp\\ipykernel_22940\\3938519938.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['Saving_All_Ratio'] = data['Saving_All'] / data['Saving_Total']\n",
      "C:\\Users\\ouhsj\\AppData\\Local\\Temp\\ipykernel_22940\\3938519938.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['Saving_Wife_Ratio'] = data['Saving_Wife']  / data['Saving_Total']\n",
      "C:\\Users\\ouhsj\\AppData\\Local\\Temp\\ipykernel_22940\\3938519938.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['Saving_Husband_Ratio'] = data['Saving_Husband'] / data['Saving_Total']\n",
      "C:\\Users\\ouhsj\\AppData\\Local\\Temp\\ipykernel_22940\\3938519938.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['Saving_Child_Ratio'] = data['Saving_Child'] / data['Saving_Total']\n",
      "C:\\Users\\ouhsj\\AppData\\Local\\Temp\\ipykernel_22940\\3938519938.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['Saving_Other_Ratio'] = data['Saving_Other'] / data['Saving_Total']\n",
      "C:\\Users\\ouhsj\\AppData\\Local\\Temp\\ipykernel_22940\\3938519938.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['Saving_Public'] = data['Saving_All'] + data['Saving_Other']\n",
      "C:\\Users\\ouhsj\\AppData\\Local\\Temp\\ipykernel_22940\\3938519938.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['Cons_Public_Ratio'] = data['Cons_Public'] / data['Cons_Total']\n",
      "C:\\Users\\ouhsj\\AppData\\Local\\Temp\\ipykernel_22940\\3938519938.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['Saving_Public_Ratio'] = data['Saving_Public'] / data['Saving_Total']\n",
      "C:\\Users\\ouhsj\\AppData\\Local\\Temp\\ipykernel_22940\\3938519938.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['Saving_Ratio'] = data['Saving_Total'] / (data['Cons_Total'] + data['Saving_Total'])\n"
     ]
    }
   ],
   "source": [
    "data.rename(columns={'Q293A':'Cons_Total'}, inplace=True)\n",
    "data.rename(columns={'Q293B':'Cons_All'}, inplace=True)\n",
    "data.rename(columns={'Q293C':'Cons_Wife'},  inplace=True)\n",
    "data.rename(columns={'Q293E':'Cons_Husband'}, inplace=True)\n",
    "data.rename(columns={'Q293F':'Cons_Child'}, inplace=True)\n",
    "data.rename(columns={'Q293G':'Cons_Other'}, inplace=True)\n",
    "\n",
    "data.rename(columns={'Q294A':'Saving_Total'}, inplace=True)\n",
    "data.rename(columns={'Q294B':'Saving_All'}, inplace=True)\n",
    "data.rename(columns={'Q294C':'Saving_Wife'},  inplace=True)\n",
    "data.rename(columns={'Q294D':'Saving_Husband'}, inplace=True)\n",
    "data.rename(columns={'Q294E':'Saving_Child'}, inplace=True)\n",
    "data.rename(columns={'Q294F':'Saving_Other'},   inplace=True)\n",
    "\n",
    "data['Cons_All_Ratio'] = data['Cons_All'] / data['Cons_Total']\n",
    "data['Cons_Wife_Ratio'] = data['Cons_Wife']  / data['Cons_Total']\n",
    "data['Cons_Husband_Ratio'] = data['Cons_Husband'] / data['Cons_Total']\n",
    "data['Cons_Child_Ratio'] = data['Cons_Child'] / data['Cons_Total']\n",
    "data['Cons_Other_Ratio'] = data['Cons_Other'] / data['Cons_Total']\n",
    "\n",
    "data['Cons_Public'] = data['Cons_All'] + data['Cons_Other']\n",
    "\n",
    "data['Saving_All_Ratio'] = data['Saving_All'] / data['Saving_Total']\n",
    "data['Saving_Wife_Ratio'] = data['Saving_Wife']  / data['Saving_Total']\n",
    "data['Saving_Husband_Ratio'] = data['Saving_Husband'] / data['Saving_Total']\n",
    "data['Saving_Child_Ratio'] = data['Saving_Child'] / data['Saving_Total']\n",
    "data['Saving_Other_Ratio'] = data['Saving_Other'] / data['Saving_Total']\n",
    "\n",
    "data['Saving_Public'] = data['Saving_All'] + data['Saving_Other']\n",
    "\n",
    "data['Cons_Public_Ratio'] = data['Cons_Public'] / data['Cons_Total']\n",
    "data['Saving_Public_Ratio'] = data['Saving_Public'] / data['Saving_Total']\n",
    "\n",
    "data['Saving_Ratio'] = data['Saving_Total'] / (data['Cons_Total'] + data['Saving_Total'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 家計の管理タイプ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#下のように整形するとWarningが出るので，処理を行う列に対してのみ処理を行う．\n",
    "#data['Q283'] = data['Q283'].apply(lambda x: np.nan if isinstance(x, (int, float)) and x >= 19 else x)\n",
    "\n",
    "#家計の管理タイプ\n",
    "def func_HH_Type(x):\n",
    "    if np.isnan(x):\n",
    "        return np.nan  # NaNの場合\n",
    "    elif 15 <= x <= 18 or x == 9 or 4 <= x <= 5:\n",
    "        return 'Wife'  # 妻が管理\n",
    "    elif 11 <= x <= 14 or 2 <= x <= 3:\n",
    "        return 'Joint'  # 共同で管理\n",
    "    elif 6 <= x <= 8:\n",
    "        return 'Husband'  # 夫が管理\n",
    "    elif x == 10:\n",
    "        return 'Separate'  # 別々で管理\n",
    "    elif x == 1:\n",
    "        return 'No_Income'  # 夫婦共に収入なし\n",
    "    else:\n",
    "        return None  # 該当なしの場合\n",
    "\n",
    "# Apply transformations to 'Q283' and 'HH_Type'\n",
    "Q283_transformed = data['Q283'].apply(lambda x: np.nan if isinstance(x, (int, float)) and x >= 19 else x)\n",
    "HH_Type = Q283_transformed.apply(func_HH_Type)\n",
    "\n",
    "# Update the DataFrame using pd.concat()\n",
    "data = pd.concat([data.drop(columns=['Q283']), Q283_transformed.rename('Q283'), HH_Type.rename('HH_Type')], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 「夫から妻」「妻から夫」に渡す金額"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 夫から妻に渡した額\n",
    "data['Q271'] = data['Q271'].apply(lambda x: np.nan if isinstance(x, (int, float)) and x >= 998 else x)\n",
    "data['Q278'] = data['Q278'].apply(lambda x: np.nan if isinstance(x, (int, float)) and x >= 998 else x)\n",
    "\n",
    "# 妻から夫に渡した額\n",
    "data['Q274'] = data['Q274'].apply(lambda x: np.nan if isinstance(x, (int, float)) and x >= 998 else x)\n",
    "\n",
    "# 夫のお小遣い\n",
    "data['Q284'] = data['Q284'].apply(lambda x: np.nan if isinstance(x, (int, float)) and x >= 998 else x)\n",
    "\n",
    "data['Q271'] = data['Q271'].apply(lambda x: x/10)\n",
    "data['Q274'] = data['Q274'].apply(lambda x: x/10)\n",
    "data['Q278'] = data['Q278'].apply(lambda x: x/10)\n",
    "data['Q284'] = data['Q284'].apply(lambda x: x/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ouhsj\\AppData\\Local\\Temp\\ipykernel_22940\\4145279653.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[\"Transfer_Money\"] = np.nan\n"
     ]
    }
   ],
   "source": [
    "# 初期設定\n",
    "data[\"Transfer_Money\"] = np.nan\n",
    "\n",
    "# 関数を定義して条件に基づいて値を設定\n",
    "def calculate_transfere_money(row):\n",
    "    # 15 <= Q283 <= 18 または 4 <= Q283 <= 5 の場合\n",
    "    if 15 <= row[\"Q283\"] <= 18 or 4 <= row[\"Q283\"] <= 5:\n",
    "        return row[\"H_Inc_Sept\"]\n",
    "    \n",
    "    # 2 <= Q283 <= 3 の場合\n",
    "    elif 2 <= row[\"Q283\"] <= 3:\n",
    "        if pd.isna(row[\"Q271\"]):  # Q271 が欠損値の場合\n",
    "            return row[\"H_Inc_Sept\"] * 0.5\n",
    "        else:\n",
    "            return row[\"Q271\"]\n",
    "    \n",
    "    # 11 <= Q283 <= 14 の場合\n",
    "    elif 11 <= row[\"Q283\"] <= 14:\n",
    "        if pd.isna(row[\"Q278\"]):  # Q278 が欠損値の場合\n",
    "            return row[\"H_Inc_Sept\"] * 0.5\n",
    "        else:\n",
    "            return row[\"Q278\"]\n",
    "\n",
    "    # Q283 == 6 の場合\n",
    "    elif row[\"Q283\"] == 6:\n",
    "        if pd.isna(row[\"Q274\"]):  # Q274 が欠損値の場合\n",
    "            return -row[\"W_Inc_Sept\"] * 0.5\n",
    "        else:\n",
    "            return -(row[\"W_Inc_Sept\"] - row[\"Q274\"])\n",
    "\n",
    "    # 7 <= Q283 <= 8 の場合\n",
    "    elif 7 <= row[\"Q283\"] <= 8:\n",
    "            return -row[\"W_Inc_Sept\"]\n",
    "    \n",
    "    # Q283 が 9, 1, 10 の場合は 0\n",
    "    elif row[\"Q283\"] in [9, 1, 10]:\n",
    "        return 0\n",
    "    \n",
    "    # デフォルトでは np.nan\n",
    "    return np.nan\n",
    "\n",
    "# apply 関数を使って行ごとに計算\n",
    "data[\"Transfer_Money\"] = data.apply(calculate_transfere_money, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[\"Transfered_Money\"]の値に基づいて、1, 0, -1を返す新しい列を作成\n",
    "data[\"Transfer_Type\"] = np.sign(data[\"Transfer_Money\"])\n",
    "data[\"Transfer_Type\"] = data[\"Transfer_Type\"].map({1: \"Husband_to_Wife\", 0: \"No_Transfer\", -1: \"Wife_to_Husband\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.03477608206154616, 0.022288261515601784)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q283が2から3の範囲の行において、Q271が欠損値である割合を計算\n",
    "q283_range_1 = data[(data[\"Q283\"] >= 2) & (data[\"Q283\"] <= 3)]\n",
    "missing_q271_ratio = q283_range_1[\"Q271\"].isna().mean()\n",
    "\n",
    "# Q283が11から14の範囲の行において、Q278が欠損値である割合を計算\n",
    "q283_range_2 = data[(data[\"Q283\"] >= 11) & (data[\"Q283\"] <= 14)]\n",
    "missing_q278_ratio = q283_range_2[\"Q278\"].isna().mean()\n",
    "\n",
    "missing_q271_ratio, missing_q278_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# お金の渡す金額が，夫の収入に占める割合\n",
    "data['Transfer_Ratio'] = data['Transfer_Money'] / data['H_Inc_Sept']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 就業状態"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Q142'] = data['Q142'].replace({\n",
    "    1: 'Working',\n",
    "    2: 'Student',\n",
    "    3: 'Housewife',\n",
    "    4: 'Other'\n",
    "})\n",
    "data['Q142'] = data['Q142'].apply(lambda x: np.nan if isinstance(x, (int, float)) and x >= 5 else x)\n",
    "\n",
    "data['Q1025'] = data['Q1025'].replace({\n",
    "    1: 'Working',\n",
    "    2: 'Working',\n",
    "    3: 'Student',\n",
    "    4: 'Housewife',\n",
    "    5: 'Other'\n",
    "})\n",
    "data['Q1025'] = data['Q1025'].apply(lambda x: np.nan if isinstance(x, (int, float)) and x >= 6 else x)\n",
    "\n",
    "# 'Q142' 列の値を優先し、'Q1025' の値が欠損値でない場合は 'Q1025' を使用\n",
    "data['Working_Status'] = data['Q142'].fillna(data['Q1025'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Q147'] = data['Q147'].replace({\n",
    "    1: 'Regular',\n",
    "    2: 'Part-time',\n",
    "    3: 'Other'\n",
    "})\n",
    "data['Q147'] = data['Q147'].apply(lambda x: np.nan if isinstance(x, (int, float)) and x >= 4 else x)\n",
    "\n",
    "data['Q1112'] = data['Q1112'].replace({\n",
    "    1: 'Regular',\n",
    "    2: 'Dispatch',\n",
    "    3: 'Fixed-term',\n",
    "    4: 'Part-time',\n",
    "    5: 'Other'\n",
    "})\n",
    "data['Q1112'] = data['Q1112'].apply(lambda x: np.nan if isinstance(x, (int, float)) and x >= 6 else x)\n",
    "\n",
    "# 'Q142' 列の値を優先し、'Q1025' の値が欠損値でない場合は 'Q1025' を使用\n",
    "data['Contract_Type'] = data['Q1112'].fillna(data['Q147'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 変数名の変更"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={'Q57': 'N_child'}, inplace=True)\n",
    "data[\"log_N_child\"] = np.log1p(data[\"N_child\"]+ 1)\n",
    "\n",
    "data.rename(columns={'Q493A':'W_Commute_Time'}, inplace=True)\n",
    "data.rename(columns={'Q495A':'H_Commute_Time'}, inplace=True)\n",
    "data.rename(columns={'Q493B':'W_Work_Time'}, inplace=True)\n",
    "data.rename(columns={'Q495B':'H_Work_Time'}, inplace=True)\n",
    "data.rename(columns={'Q493C':'W_Study_Time'}, inplace=True)\n",
    "data.rename(columns={'Q495C':'H_Study_Time'}, inplace=True)\n",
    "data.rename(columns={'Q493D':'W_Chore_ChildCare_Time'}, inplace=True)\n",
    "data.rename(columns={'Q495D':'H_Chore_ChildCare_Time'}, inplace=True)\n",
    "data.rename(columns={'Q493I':'W_Hobby_Time'}, inplace=True)\n",
    "data.rename(columns={'Q495I':'H_Hobby_Time'}, inplace=True)\n",
    "data.rename(columns={'Q493M':'W_Sleep_Time'}, inplace=True)\n",
    "data.rename(columns={'Q495M':'H_Sleep_Time'}, inplace=True)\n",
    "\n",
    "\n",
    "#---------------------------------------------------\n",
    "data['W_Market_Time'] = data['W_Commute_Time'] + data['W_Work_Time']\n",
    "data['H_Market_Time'] = data['H_Commute_Time'] + data['H_Work_Time']\n",
    "\n",
    "data['W_Leisure_Time'] = data['W_Hobby_Time'] + data['W_Sleep_Time']\n",
    "data['H_Leisure_Time'] = data['H_Hobby_Time'] + data['H_Sleep_Time']\n",
    "\n",
    "data['W_Total_Time'] = data['W_Market_Time'] + data['W_Study_Time'] + data['W_Chore_ChildCare_Time'] + data['W_Leisure_Time']\n",
    "data['H_Total_Time'] = data['H_Market_Time'] + data['H_Study_Time'] + data['H_Chore_ChildCare_Time'] + data['H_Leisure_Time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={'Q1233A':'H_Chore_Ratio'}, inplace=True)\n",
    "data.rename(columns={'Q1233B':'W_Chore_Ratio'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データ書き出し"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの容量を圧縮\n",
    "# 元の列名と現在の列名を比較\n",
    "original_columns = set(data_original.columns)\n",
    "current_columns = set(data.columns)\n",
    "\n",
    "# 元のデータフレームにない新しい列を抽出\n",
    "new_columns = current_columns - original_columns\n",
    "\n",
    "# 常に保持する列 (IDとPANEL) を追加\n",
    "columns_to_keep = ['ID', 'PANEL'] + list(new_columns)\n",
    "\n",
    "# 新しい列だけを含むデータフレームを作成\n",
    "data_to_csv = data[list(columns_to_keep)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ書き出し\n",
    "data_to_csv.to_csv('../Data_JPSC/data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
